{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9779709,"sourceType":"datasetVersion","datasetId":5991214},{"sourceId":9794107,"sourceType":"datasetVersion","datasetId":6001830}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:18.503762Z","iopub.execute_input":"2024-11-08T17:40:18.504041Z","iopub.status.idle":"2024-11-08T17:40:50.211952Z","shell.execute_reply.started":"2024-11-08T17:40:18.504010Z","shell.execute_reply":"2024-11-08T17:40:50.210993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import torch\n# from torch.utils.data import Dataset, DataLoader\n# from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n\n# # Load the datasets\n# train_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_train.csv')\n# valid_df = pd.read_csv('/kaggle/input/hs-cs-kn-valid/hscnkp_valid.csv')\n# test_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_test.csv')\n# train_df.dropna(inplace=True)\n# valid_df.dropna(inplace=True)\n# test_df.dropna(inplace=True)\n\n# # Define custom tokens and a task prompt for generation\n# HS_TOKEN = \"<HS>\"\n# KNOWL_TOKEN = \"<knowl>\"\n# CN_TOKEN = \"<CN>\"\n# TASK_PROMPT = \"Generate a counter narrative: \"\n\n# # Prepare the input data with custom tokens and the task prompt\n# train_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + train_df['hate_speech'] + \" \" + KNOWL_TOKEN + \" \" +\n#     train_df['knowledge_sentence'] + \" \" + CN_TOKEN + \" \" +\n#     train_df['counter_narrative']\n# )\n\n# valid_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + valid_df['hate_speech'] + \" \" + KNOWL_TOKEN + \" \" +\n#     valid_df['knowledge_sentence'] + \" \" + CN_TOKEN + \" \" +\n#     valid_df['counter_narrative']\n# )\n\n# test_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + test_df['hate_speech'] + \" \" + KNOWL_TOKEN + \" \" +\n#     test_df['knowledge_sentence'] + \" \" + CN_TOKEN\n# )\n\n# # Convert to lists\n# train_inputs = train_df['input'].tolist()\n# valid_inputs = valid_df['input'].tolist()\n# test_inputs = test_df['input'].tolist()\n\n# class CustomDataset(Dataset):\n#     def __init__(self, inputs, tokenizer, max_length=512):\n#         self.inputs = inputs\n#         self.tokenizer = tokenizer\n#         self.max_length = max_length\n\n#     def __len__(self):\n#         return len(self.inputs)\n\n#     def __getitem__(self, idx):\n#         encoding = self.tokenizer(\n#             self.inputs[idx],\n#             padding=\"max_length\",\n#             truncation=True,\n#             max_length=self.max_length,\n#             return_tensors=\"pt\"\n#         )\n        \n#         input_ids = encoding[\"input_ids\"].squeeze()\n#         attention_mask = encoding[\"attention_mask\"].squeeze()\n\n#         return {\n#             'input_ids': input_ids,\n#             'attention_mask': attention_mask,\n#             'labels': input_ids\n#         }\n\n# # Load tokenizer and model\n# model_name = \"google/flan-t5-small\"\n# tokenizer = T5Tokenizer.from_pretrained(model_name)\n# model = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# # Add custom tokens\n# special_tokens_dict = {\n#     'additional_special_tokens': [HS_TOKEN, KNOWL_TOKEN, CN_TOKEN]\n# }\n# tokenizer.add_special_tokens(special_tokens_dict)\n# model.resize_token_embeddings(len(tokenizer))\n\n# # Create datasets\n# train_dataset = CustomDataset(train_inputs, tokenizer)\n# valid_dataset = CustomDataset(valid_inputs, tokenizer)\n# test_dataset = CustomDataset(test_inputs, tokenizer)\n\n# # Set up training arguments\n# training_args = TrainingArguments(\n#     output_dir='./results',\n#     num_train_epochs=3,\n#     per_device_train_batch_size=4,\n#     per_device_eval_batch_size=4,\n#     warmup_steps=500,\n#     weight_decay=0.01,\n#     logging_dir='./logs',\n#     logging_steps=10,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     save_total_limit=2,\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"loss\",\n#     report_to=[]\n# )\n\n# # Initialize the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=valid_dataset\n# )\n\n# # Suppress specific warnings temporarily\n# import warnings\n# warnings.filterwarnings(\"ignore\", category=UserWarning)\n# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# # Train the model\n# trainer.train()\n\n# # Save model and tokenizer after training\n# trainer.save_model('./results/fine-tuned-flan-t5')\n# tokenizer.save_pretrained('./results/fine-tuned-flan-t5')\n\n# # Model evaluation mode\n# model.eval()\n\n# # Example of generating counter narratives for inputs from the test set\n# for example_input in test_inputs[:5]:  # Adjust range for more examples\n#     input_ids = tokenizer.encode(TASK_PROMPT + example_input, return_tensors='pt').to(model.device)\n#     output = model.generate(\n#         input_ids,\n#         max_length=512,\n#         num_return_sequences=1,\n#         attention_mask=input_ids.ne(tokenizer.pad_token_id),\n#         num_beams=5,\n#         early_stopping=True\n#     )\n\n#     generated_counter_narrative = tokenizer.decode(output[0], skip_special_tokens=False)\n#     print(f\"Input: {example_input}\\nGenerated Counter Narrative: {generated_counter_narrative}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:50.213891Z","iopub.execute_input":"2024-11-08T17:40:50.214492Z","iopub.status.idle":"2024-11-08T17:40:50.224410Z","shell.execute_reply.started":"2024-11-08T17:40:50.214456Z","shell.execute_reply":"2024-11-08T17:40:50.223405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import torch\n# from torch.utils.data import Dataset, DataLoader\n# from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n\n# # Load the datasets\n# train_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_train.csv')\n# valid_df = pd.read_csv('/kaggle/input/hs-cs-kn-valid/hscnkp_valid.csv')\n# test_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_test.csv')\n# train_df.dropna(inplace=True)\n# valid_df.dropna(inplace=True)\n# test_df.dropna(inplace=True)\n\n# # Define custom tokens and task prompt\n# HS_TOKEN = \"<HS>\"\n# KN_TOKEN = \"<KN>\"\n# CN_TOKEN = \"<CN>\"\n# TASK_PROMPT = \"Generate a counter narrative: \"\n\n# # Prepare input and target data separately\n# train_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + train_df['hate_speech'] + \" \" + KN_TOKEN + \" \" +\n#     train_df['knowledge_sentence'] + \" \" + CN_TOKEN\n# )\n# train_df['target'] = train_df['counter_narrative']\n\n# valid_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + valid_df['hate_speech'] + \" \" + KN_TOKEN + \" \" +\n#     valid_df['knowledge_sentence'] + \" \" + CN_TOKEN\n# )\n# valid_df['target'] = valid_df['counter_narrative']\n\n# test_df['input'] = (\n#     TASK_PROMPT + HS_TOKEN + \" \" + test_df['hate_speech'] + \" \" + KN_TOKEN + \" \" +\n#     test_df['knowledge_sentence'] + \" \" + CN_TOKEN\n# )\n\n# # Convert to lists\n# train_inputs = train_df['input'].tolist()\n# train_targets = train_df['target'].tolist()\n# valid_inputs = valid_df['input'].tolist()\n# valid_targets = valid_df['target'].tolist()\n# test_inputs = test_df['input'].tolist()\n\n# class CustomDataset(Dataset):\n#     def __init__(self, inputs, targets, tokenizer, max_length=512):\n#         self.inputs = inputs\n#         self.targets = targets\n#         self.tokenizer = tokenizer\n#         self.max_length = max_length\n\n#     def __len__(self):\n#         return len(self.inputs)\n\n#     def __getitem__(self, idx):\n#         encoding = self.tokenizer(\n#             self.inputs[idx],\n#             padding=\"max_length\",\n#             truncation=True,\n#             max_length=self.max_length,\n#             return_tensors=\"pt\"\n#         )\n#         target_encoding = self.tokenizer(\n#             self.targets[idx],\n#             padding=\"max_length\",\n#             truncation=True,\n#             max_length=self.max_length,\n#             return_tensors=\"pt\"\n#         )\n        \n#         input_ids = encoding[\"input_ids\"].squeeze()\n#         attention_mask = encoding[\"attention_mask\"].squeeze()\n#         labels = target_encoding[\"input_ids\"].squeeze()\n\n#         # Replace pad tokens in labels with -100 to ignore them in loss calculation\n#         labels[labels == self.tokenizer.pad_token_id] = -100\n\n#         return {\n#             'input_ids': input_ids,\n#             'attention_mask': attention_mask,\n#             'labels': labels\n#         }\n\n# # Load tokenizer and model\n# model_name = \"google/flan-t5-small\"\n# tokenizer = T5Tokenizer.from_pretrained(model_name)\n# model = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# # Add custom tokens\n# special_tokens_dict = {\n#     'additional_special_tokens': [HS_TOKEN, KN_TOKEN, CN_TOKEN]\n# }\n# tokenizer.add_special_tokens(special_tokens_dict)\n# model.resize_token_embeddings(len(tokenizer))\n\n# # Create datasets\n# train_dataset = CustomDataset(train_inputs, train_targets, tokenizer)\n# valid_dataset = CustomDataset(valid_inputs, valid_targets, tokenizer)\n\n# # Set up training arguments\n# training_args = TrainingArguments(\n#     output_dir='./results',\n#     num_train_epochs=3,\n#     per_device_train_batch_size=4,\n#     per_device_eval_batch_size=4,\n#     warmup_steps=500,\n#     weight_decay=0.01,\n#     logging_dir='./logs',\n#     logging_steps=10,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     save_total_limit=2,\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"loss\",\n#     report_to=[]\n# )\n\n# # Initialize the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=valid_dataset\n# )\n\n# # Train the model\n# trainer.train()\n\n# # Save model and tokenizer after training\n# trainer.save_model('./results/fine-tuned-flan-t5')\n# tokenizer.save_pretrained('./results/fine-tuned-flan-t5')\n\n# # Model evaluation mode\n# model.eval()\n\n# # Example of generating counter narratives for inputs from the test set\n# for example_input in test_inputs[:5]:  # Adjust range for more examples\n#     input_ids = tokenizer.encode(example_input, return_tensors='pt').to(model.device)\n#     output = model.generate(\n#         input_ids,\n#         max_length=100,\n#         num_return_sequences=1,\n#         attention_mask=input_ids.ne(tokenizer.pad_token_id),\n#         num_beams=5,\n#         early_stopping=True\n#     )\n\n#     generated_counter_narrative = tokenizer.decode(output[0], skip_special_tokens=True)\n#     print(f\"Input: {example_input}\\nGenerated Counter Narrative: {generated_counter_narrative}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:50.225554Z","iopub.execute_input":"2024-11-08T17:40:50.226062Z","iopub.status.idle":"2024-11-08T17:40:50.246951Z","shell.execute_reply.started":"2024-11-08T17:40:50.226023Z","shell.execute_reply":"2024-11-08T17:40:50.246216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n\n# Load the datasets\ntrain_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_train.csv')  # Adjust file name for training data\nvalid_df = pd.read_csv('/kaggle/input/hs-cs-kn-valid/hscnkp_valid.csv')  # Adjust file name for validation data\ntest_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_test.csv')    # Adjust file name for test data\ntrain_df.dropna(inplace=True)\nvalid_df.dropna(inplace=True)\ntest_df.dropna(inplace=True)\n\n# Define custom tokens\nHS_TOKEN = \"<HS>\"\nKN_TOKEN = \"<KN>\"\nCN_TOKEN = \"<CN>\"\n\n# Prepare the input data with custom tokens\ntrain_df['input'] = (\n    HS_TOKEN + train_df['hate_speech'] + KN_TOKEN +\n    train_df['knowledge_sentence'] + CN_TOKEN +\n    train_df['counter_narrative']\n)\n\nvalid_df['input'] = (\n    HS_TOKEN + valid_df['hate_speech'] + KN_TOKEN +\n    valid_df['knowledge_sentence'] + CN_TOKEN +\n    valid_df['counter_narrative']\n)\n\ntest_df['input'] = (\n    HS_TOKEN + test_df['hate_speech'] + KN_TOKEN +\n    test_df['knowledge_sentence'] + CN_TOKEN\n)\n\n# Convert to lists\ntrain_inputs = train_df['input'].tolist()\nvalid_inputs = valid_df['input'].tolist()\ntest_inputs = test_df['input'].tolist()\n\nclass CustomDataset(Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        # Tokenize input for GPT-2\n        input_ids = self.tokenizer.encode(self.inputs[idx], truncation=True, padding='max_length', max_length=512)\n        \n        # The labels should be the same as the input but shifted to the left by one token\n        # This way, the model learns to predict the next token.\n        labels = input_ids.copy()\n        return {\n            'input_ids': torch.tensor(input_ids),  # Ensure input_ids are tensors\n            'labels': torch.tensor(labels)          # Ensure labels are tensors\n        }\n\n# Load tokenizer and model\nmodel_name = 'gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token \n\n# Add special tokens to the tokenizer\nspecial_tokens_dict = {\n    'additional_special_tokens': [HS_TOKEN, KN_TOKEN, CN_TOKEN]\n}\nnum_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n\n# Resize the model's token embeddings to accommodate new tokens\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\n\n# tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos token\n\n# Create datasets\ntrain_dataset = CustomDataset(train_inputs, tokenizer)\nvalid_dataset = CustomDataset(valid_inputs, tokenizer)\ntest_dataset = CustomDataset(test_inputs, tokenizer)\n\n# Create DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:50.249658Z","iopub.execute_input":"2024-11-08T17:40:50.250187Z","iopub.status.idle":"2024-11-08T17:40:55.463600Z","shell.execute_reply.started":"2024-11-08T17:40:50.250154Z","shell.execute_reply":"2024-11-08T17:40:55.462740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.isnull().sum())  # Check for missing values in the training DataFrame\nprint(valid_df.isnull().sum())  # Check for missing values in the validation DataFrame\nprint(test_df.isnull().sum())   # Check for missing values in the test DataFrame\nprint(train_df.shape)\nprint(valid_df.shape)\nprint(test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:55.465093Z","iopub.execute_input":"2024-11-08T17:40:55.465710Z","iopub.status.idle":"2024-11-08T17:40:55.479511Z","shell.execute_reply.started":"2024-11-08T17:40:55.465662Z","shell.execute_reply":"2024-11-08T17:40:55.477467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',                # Output directory\n    num_train_epochs=3,                    # Number of training epochs\n    per_device_train_batch_size=4,         # Batch size for training\n    per_device_eval_batch_size=4,          # Batch size for evaluation\n    warmup_steps=500,                       # Warmup steps\n    weight_decay=0.01,                     # Strength of weight decay\n    logging_dir='./logs',                   # Directory for storing logs\n    logging_steps=10,                       # Log every 10 steps\n    evaluation_strategy=\"epoch\",            # Evaluate every epoch\n    save_strategy=\"epoch\",                  # Save model at the end of each epoch\n    save_total_limit=2,                     # Limit the total amount of checkpoints\n    load_best_model_at_end=True,           # Load the best model when finished training\n    metric_for_best_model=\"loss\",           # Specify the metric to use to compare models\n    report_to=[],                           # Disable wandb\n) \n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,                            # The instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                     # Training arguments, defined above\n    train_dataset=train_dataset,            # Training dataset\n    eval_dataset=valid_dataset               # Validation dataset\n)\n\n# Train the model\ntrainer.train()\n\n# Save the model and tokenizer after each epoch\ntrainer.save_model('./results/fine-tuned-gpt')\ntokenizer.save_pretrained('./results/fine-tuned-gpt')\n\n# To generate counter narratives, use the model after training:\nmodel.eval()  # Switch model to evaluation mode\nmodel.config.pad_token_id = tokenizer.eos_token_id\n# Example of generating counter narratives for inputs from the test set\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T17:40:55.480944Z","iopub.execute_input":"2024-11-08T17:40:55.481304Z","iopub.status.idle":"2024-11-08T18:02:04.729115Z","shell.execute_reply.started":"2024-11-08T17:40:55.481262Z","shell.execute_reply":"2024-11-08T18:02:04.728251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# List to store data for the CSV file\noutput_data = []\n\nfor example_input in test_inputs[-5:]:  # Adjust the range as needed\n    # Extract hate_speech part from the input\n    hate_speech = example_input.split(HS_TOKEN)[1].split(KN_TOKEN)[0]\n\n    input_ids = tokenizer.encode(example_input, return_tensors='pt').to(model.device)\n\n    # Generate 2 counter-narratives with nucleus sampling\n    outputs = model.generate(\n        input_ids,\n        max_length=512,\n        num_return_sequences=2,  # Generate 2 counter-narratives\n        do_sample=True,          # Enable sampling instead of greedy decoding\n        top_p=0.9,               # Set top_p for nucleus sampling\n        temperature=1.0          # Adjust temperature for randomness\n    )\n\n    # Decode the generated counter-narratives\n    counter_narratives = []\n    for output in outputs:\n        generated_text = tokenizer.decode(output, skip_special_tokens=True)\n        # Extract counter narrative part from the generated output\n        counter_narrative = generated_text.split(CN_TOKEN)[-1]\n        counter_narratives.append(counter_narrative.strip())\n\n    # Append the data to the list\n    output_data.append({\n        'hate_speech': hate_speech.strip(),\n        'counter_narrative1': counter_narratives[0] if len(counter_narratives) > 0 else \"\",\n        'counter_narrative2': counter_narratives[1] if len(counter_narratives) > 1 else \"\"\n    })\n\n# Convert list to DataFrame and save to CSV\noutput_df = pd.DataFrame(output_data)\noutput_df.to_csv('gpt2-out.csv', index=False)\n\nprint(\"CSV file 'generated_counter_narratives.csv' created successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:04.730244Z","iopub.execute_input":"2024-11-08T18:02:04.730575Z","iopub.status.idle":"2024-11-08T18:02:07.849825Z","shell.execute_reply.started":"2024-11-08T18:02:04.730543Z","shell.execute_reply":"2024-11-08T18:02:07.848844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for example_input in test_inputs[100:120:2]:  # Change the range for more inputs\n#     input_ids = tokenizer.encode(example_input, return_tensors='pt').to(model.device)\n#     output = model.generate(input_ids, max_length=512, num_return_sequences=1)\n\n#     # Decode the generated tokens to string\n#     generated_counter_narrative = tokenizer.decode(output[0], skip_special_tokens=False)\n#     print(f\"Input: {example_input}\\nGenerated Counter Narrative: {generated_counter_narrative}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:07.851183Z","iopub.execute_input":"2024-11-08T18:02:07.851612Z","iopub.status.idle":"2024-11-08T18:02:07.856647Z","shell.execute_reply.started":"2024-11-08T18:02:07.851567Z","shell.execute_reply":"2024-11-08T18:02:07.855471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# example_input = (\n#     \"<HS> A school in Birmingham is still separating girls from boys. \"\n#     \"<knowl> The school was described in its 2006 Ofsted report as outstanding. \"\n#     \"<CN>\"\n# )\n\n# input_ids = tokenizer.encode(example_input, return_tensors='pt').to(model.device)\n# output = model.generate(input_ids, max_length=100, top_p=0.9,num_return_sequences=1)\n\n# # Decode the generated tokens to string\n# generated_counter_narrative = tokenizer.decode(output[0])\n# print(generated_counter_narrative)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:07.857947Z","iopub.execute_input":"2024-11-08T18:02:07.858628Z","iopub.status.idle":"2024-11-08T18:02:09.389541Z","shell.execute_reply.started":"2024-11-08T18:02:07.858583Z","shell.execute_reply":"2024-11-08T18:02:09.388639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_test.csv')\n# test_df = pd.read_csv('/kaggle/input/hs-cs-kn/hscnkp_test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.393373Z","iopub.execute_input":"2024-11-08T18:02:09.394017Z","iopub.status.idle":"2024-11-08T18:02:09.399347Z","shell.execute_reply.started":"2024-11-08T18:02:09.393980Z","shell.execute_reply":"2024-11-08T18:02:09.398462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# HS_START = \"<HS-start>\"\n# HS_END = \"<HS-end>\"\n# KN_START = \"<KN-start>\"\n# KN_END = \"<KN-end>\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.400579Z","iopub.execute_input":"2024-11-08T18:02:09.400884Z","iopub.status.idle":"2024-11-08T18:02:09.409531Z","shell.execute_reply.started":"2024-11-08T18:02:09.400853Z","shell.execute_reply":"2024-11-08T18:02:09.408832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df['input'] = (\n#     HS_START + ' ' + train_df['hate_speech'] + ' ' + HS_END + ' ' +\n#     KN_START + ' ' + train_df['knowledge_sentence'] + ' ' + KN_END\n# )\n# train_df['output'] = train_df['counter_narrative']\n\n# test_df['input'] = (\n#     HS_START + ' ' + test_df['hate_speech'] + ' ' + HS_END + ' ' +\n#     KN_START + ' ' + test_df['knowledge_sentence'] + ' ' + KN_END\n# )\n# test_df['output'] = test_df['counter_narrative']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.410689Z","iopub.execute_input":"2024-11-08T18:02:09.411020Z","iopub.status.idle":"2024-11-08T18:02:09.431726Z","shell.execute_reply.started":"2024-11-08T18:02:09.410989Z","shell.execute_reply":"2024-11-08T18:02:09.430818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_inputs = train_df['input'].tolist()\n# train_outputs = train_df['output'].tolist()\n# test_inputs = test_df['input'].tolist()\n# test_outputs = test_df['output'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.432799Z","iopub.execute_input":"2024-11-08T18:02:09.433143Z","iopub.status.idle":"2024-11-08T18:02:09.441162Z","shell.execute_reply.started":"2024-11-08T18:02:09.433100Z","shell.execute_reply":"2024-11-08T18:02:09.440458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(train_inputs[0])\n# print(train_outputs[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.442173Z","iopub.execute_input":"2024-11-08T18:02:09.442491Z","iopub.status.idle":"2024-11-08T18:02:09.451623Z","shell.execute_reply.started":"2024-11-08T18:02:09.442455Z","shell.execute_reply":"2024-11-08T18:02:09.450828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n# special_tokens = [HS_START, HS_END, KN_START, KN_END]\n# tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n# tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.452816Z","iopub.execute_input":"2024-11-08T18:02:09.453576Z","iopub.status.idle":"2024-11-08T18:02:09.461055Z","shell.execute_reply.started":"2024-11-08T18:02:09.453533Z","shell.execute_reply":"2024-11-08T18:02:09.460201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class CustomDataset(Dataset):\n#     def __init__(self, inputs, outputs, tokenizer):\n#         self.inputs = inputs\n#         self.outputs = outputs\n#         self.tokenizer = tokenizer\n\n#     def __len__(self):\n#         return len(self.inputs)\n\n#     def __getitem__(self, idx):\n#         # Encode inputs and outputs with custom tokens\n#         input_ids = self.tokenizer.encode(self.inputs[idx], truncation=True, padding='max_length', max_length=512)\n#         labels = self.tokenizer.encode(self.outputs[idx], truncation=True, padding='max_length', max_length=512)\n#         return {\n#             'input_ids': torch.tensor(input_ids),  # Ensure input_ids are tensors\n#             'labels': torch.tensor(labels)         # Ensure labels are tensors\n#         }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.462203Z","iopub.execute_input":"2024-11-08T18:02:09.462492Z","iopub.status.idle":"2024-11-08T18:02:09.471669Z","shell.execute_reply.started":"2024-11-08T18:02:09.462456Z","shell.execute_reply":"2024-11-08T18:02:09.470811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Load the model and move it to the GPU if available\n# model = GPT2LMHeadModel.from_pretrained('gpt2')\n# model.resize_token_embeddings(len(tokenizer))\n# model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.472694Z","iopub.execute_input":"2024-11-08T18:02:09.472971Z","iopub.status.idle":"2024-11-08T18:02:09.480344Z","shell.execute_reply.started":"2024-11-08T18:02:09.472927Z","shell.execute_reply":"2024-11-08T18:02:09.479517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_dataset = CustomDataset(train_inputs, train_outputs, tokenizer)\n# test_dataset = CustomDataset(test_inputs, test_outputs, tokenizer)\n\n# # Create DataLoader\n# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.481489Z","iopub.execute_input":"2024-11-08T18:02:09.481839Z","iopub.status.idle":"2024-11-08T18:02:09.490482Z","shell.execute_reply.started":"2024-11-08T18:02:09.481797Z","shell.execute_reply":"2024-11-08T18:02:09.489549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     output_dir='./results',                # Output directory\n#     num_train_epochs=3,                    # Number of training epochs\n#     per_device_train_batch_size=4,         # Batch size for training\n#     per_device_eval_batch_size=4,          # Batch size for evaluation\n#     warmup_steps=500,                      # Warmup steps\n#     weight_decay=0.01,                     # Strength of weight decay\n#     logging_dir='./logs',                  # Directory for storing logs\n#     logging_steps=10,                      # Log every 10 steps\n#     evaluation_strategy=\"epoch\",           # Evaluate every epoch\n#     save_strategy=\"epoch\",                 # Save model at the end of each epoch\n#     save_total_limit=2,                    # Limit the total amount of checkpoints\n#     load_best_model_at_end=True,           # Load the best model when finished training\n#     metric_for_best_model=\"loss\",          # Specify the metric to use to compare models\n#     report_to=[],                          # Disable wandb\n# )\n\n# # Initialize the Trainer\n# trainer = Trainer(\n#     model=model,                            # The instantiated ðŸ¤— Transformers model to be trained\n#     args=training_args,                     # Training arguments, defined above\n#     train_dataset=train_dataset,            # Training dataset\n#     eval_dataset=test_dataset               # Evaluation dataset\n# )\n\n# # Train the model\n# trainer.train()\n\n# model_save_path = './results/fine-tuned-gpt'\n# trainer.save_model(model_save_path)  # Save the final model\n# tokenizer.save_pretrained(model_save_path)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.491479Z","iopub.execute_input":"2024-11-08T18:02:09.491748Z","iopub.status.idle":"2024-11-08T18:02:09.504259Z","shell.execute_reply.started":"2024-11-08T18:02:09.491707Z","shell.execute_reply":"2024-11-08T18:02:09.503470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.505146Z","iopub.execute_input":"2024-11-08T18:02:09.505476Z","iopub.status.idle":"2024-11-08T18:02:09.513127Z","shell.execute_reply.started":"2024-11-08T18:02:09.505435Z","shell.execute_reply":"2024-11-08T18:02:09.512250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import GPT2LMHeadModel, GPT2Tokenizer\n# import torch\n\n# # Set up the device\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Load the fine-tuned model and tokenizer\n# model = GPT2LMHeadModel.from_pretrained('./results/fine-tuned-gpt').to(device)\n# tokenizer = GPT2Tokenizer.from_pretrained('./results/fine-tuned-gpt')\n\n# # Make sure the model is in evaluation mode\n# model.eval()\n\n# # Select a few examples from the test dataset\n# sample_inputs = test_inputs[:2]  # Adjust the number of examples as needed\n# real_counter_narratives = test_outputs[:2]  # Get the corresponding real counter narratives\n\n# # Generate outputs for each input\n# for i, input_text in enumerate(sample_inputs):\n#     # Encode the input text and move it to the correct device\n#     input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n    \n#     # Generate the output\n#     with torch.no_grad():\n#         output_ids = model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n    \n#     # Decode the output to text\n#     generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    \n#     # Print the results\n#     print(f\"Input {i + 1}: {input_text}\")\n#     print(f\"Generated Output {i + 1}: {generated_text}\")\n#     print(f\"Real Counter Narrative {i + 1}: {real_counter_narratives[i]}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:02:09.514174Z","iopub.execute_input":"2024-11-08T18:02:09.514514Z","iopub.status.idle":"2024-11-08T18:02:09.524327Z","shell.execute_reply.started":"2024-11-08T18:02:09.514479Z","shell.execute_reply":"2024-11-08T18:02:09.523639Z"}},"outputs":[],"execution_count":null}]}